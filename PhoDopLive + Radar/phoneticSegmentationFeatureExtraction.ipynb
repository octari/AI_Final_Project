{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pocketsphinx\n",
    "from pocketsphinx.pocketsphinx import *\n",
    "from sphinxbase.sphinxbase import *\n",
    "from pocketsphinx import Pocketsphinx, get_model_path, get_data_path\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from sklearn import preprocessing\n",
    "from python_speech_features import mfcc, logfbank\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phonetic segmentation using pocketsphiinx\n",
    "# feature extraction: MFCC + filterbank energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = get_model_path()\n",
    "training_data_path = \".\\data\\ASVspoof2017_V2_train\"\n",
    "dev_data_path = \".\\data\\ASVspoof2017_V2_dev\"\n",
    "data_path = \".\\data\"\n",
    "dictionary = \"ASVspoof2017_1.dict\"\n",
    "training_set_description_path = \".\\data\\protocol_V2\\ASVspoof2017_V2_train.trn.txt\"\n",
    "dev_set_description_path = \".\\data\\protocol_V2\\ASVspoof2017_V2_dev.trl.txt\"\n",
    "fileName = \"T_1000003.wav\"\n",
    "phonemes_path = \".\\data\\PasswordPhonemes.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all possible phonemes:  ['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH', 'D', 'DH', 'EH', 'ER', 'EY', 'F', 'G', 'HH', 'IH', 'IY', 'JH', 'K', 'L', 'M', 'N', 'NG', 'OW', 'OY', 'P', 'R', 'S', 'SH', 'T', 'TH', 'UW', 'V', 'W', 'Y', 'Z', 'ZH']\n"
     ]
    }
   ],
   "source": [
    "f = open(phonemes_path, \"r\")\n",
    "all_possible_phonemes =  list(set(f.read().split()))\n",
    "f.close()\n",
    "all_possible_phonemes.sort()\n",
    "print(\"all possible phonemes: \", all_possible_phonemes)\n",
    "\n",
    "\n",
    "# generate phoneme to index mapping for creating features\n",
    "# group similar phonemes together. For example, 'AA' and 'AH'.\n",
    "# some elements are set to zero because they are extremely unfrequent\n",
    "phoneme_to_index = {'AA':0, 'AE':0, 'AH':0, 'AO':0, 'AW':0, 'AY':0, 'B':1, 'CH':2, 'D':3, 'DH':3, 'EH':4, 'ER':4, \n",
    "                    'EY':4, 'F':-1, 'G':-1, 'HH':-1, 'IH':8, 'IY':8, 'JH':-1, 'K':10, 'L':11, 'M':12, 'N':12, 'NG':12, \n",
    "                    'OW':14, 'OY':14, 'P':13, 'R':9, 'S':7, 'SH':7, 'T':6, 'TH':16, 'UW':-1, 'V':15, 'W':5, \n",
    "                    'Y':17, 'Z':7, 'ZH':7}\n",
    "\n",
    "# read data description file\n",
    "f = open(training_set_description_path, \"r\")\n",
    "training_set_description = f.read().split('\\n')\n",
    "f.close()\n",
    "\n",
    "f = open(dev_set_description_path, \"r\")\n",
    "dev_set_description = f.read().split('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # count occurence of each phoneme\n",
    "# counts = {}\n",
    "# for p in all_possible_phonemes:\n",
    "#     counts[p] = 0\n",
    "# # add occurence count\n",
    "# for record in training_set_description:\n",
    "#     if len(record)>40:\n",
    "#         dictionary = \"ASVspoof2017_\"+ str(int(record.split(\" \")[3][1:])) + \".dict\"\n",
    "#         f = open(os.path.join(data_path, dictionary), \"r\")\n",
    "#         dict =  f.read()\n",
    "#         f.close()\n",
    "#         for line in dict.split(\"\\n\"):\n",
    "#             for w in line.split()[1:]:\n",
    "#                 counts[w] += 1\n",
    "# print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction through mfcc and log filter bank energy\n",
    "def extract_mfcc_filterbank_features(file_path, show=False):\n",
    "\n",
    "    sampling_frequency, signal = wavfile.read(file_path)\n",
    "\n",
    "\n",
    "    mfcc_features = mfcc(signal, sampling_frequency)\n",
    "    mfcc_features = preprocessing.scale(mfcc_features)\n",
    "    filterbank_features = logfbank(signal, sampling_frequency, nfilt=5)\n",
    "    filterbank_features = preprocessing.scale(filterbank_features)\n",
    "\n",
    "    if (show):\n",
    "        print('Sampling rate: ', sampling_frequency)\n",
    "        print('Number of samples: ', signal.shape[0])\n",
    "        print('Number of windows: ', features_mfcc.shape[0])\n",
    "#         print('Length of each feature: ', features_mfcc.shape[1])\n",
    "\n",
    "        plt.matshow(mfcc_features.T)\n",
    "        plt.title('MFCC')\n",
    "\n",
    "        plt.matshow(filterbank_features.T)\n",
    "        plt.title('Filterbank')\n",
    "    \n",
    "    return mfcc_features, filterbank_features\n",
    "\n",
    "# perform word segmentation\n",
    "def word_seg(file_path, verbose=True):\n",
    "    # set parameters and dictionary\n",
    "    config = {\n",
    "        'hmm': os.path.join(model_path, 'en-us'),\n",
    "        'lm': os.path.join(model_path, 'en-us.lm.bin'),\n",
    "        'dict': os.path.join(data_path, dictionary)\n",
    "    }\n",
    "    ps = Pocketsphinx(**config)\n",
    "\n",
    "    ps.decode(\n",
    "        audio_file=file_path,\n",
    "        buffer_size=2048,\n",
    "        no_search=False,\n",
    "        full_utt=False\n",
    "    )\n",
    "\n",
    "    segs_and_phonemes = [(seg.word, ps.lookup_word(seg.word), seg.start_frame,  seg.end_frame)  for seg in ps.seg()]\n",
    "    \n",
    "    if (verbose):\n",
    "        print(\"hypothesis: \" + ps.hypothesis()) \n",
    "\n",
    "        # print(\"word, prob, start_frame, end_frame\")\n",
    "        print('Detailed segments:', *ps.segments(detailed=True), sep='\\n')\n",
    "        \n",
    "        print('Segments Phonemes:', segs_and_phonemes)\n",
    "        \n",
    "    return segs_and_phonemes\n",
    "\n",
    "# perform phoneme recognition\n",
    "def phoneme_seg(file_path, verbose=True):\n",
    "    # Create a decoder with a certain model\n",
    "    config = pocketsphinx.Decoder.default_config()\n",
    "    config.set_string('-hmm', os.path.join(model_path, 'en-us'))\n",
    "    config.set_string('-allphone', os.path.join(model_path, \"en-us-phone.lm.bin\"))\n",
    "    config.set_string('-dict', os.path.join(data_path, dictionary))\n",
    "    config.set_float('-lw', 2.0)\n",
    "    config.set_float('-beam', 1e-20)\n",
    "    config.set_float('-pbeam', 1e-20)\n",
    "    decoder = Decoder(config)\n",
    "\n",
    "    # Decode streaming data\n",
    "    buffer = bytearray(2048)\n",
    "    f = open(file_path, 'rb')\n",
    "    decoder.start_utt()\n",
    "    while f.readinto(buffer):\n",
    "        decoder.process_raw(buffer, False, False)\n",
    "    decoder.end_utt()\n",
    "    f.close()\n",
    "    \n",
    "    segs = [(seg.word, seg.start_frame, seg.end_frame) for seg in decoder.seg()]\n",
    "    \n",
    "    if (verbose):\n",
    "        print('Best phonetic segments:', segs)\n",
    "        \n",
    "    return segs\n",
    "\n",
    "# extract MFCC and filterbank energy feature\n",
    "def extract_feature(mfcc_features, filterbank_features,  word_segments, phoneme_segments):\n",
    "    # feature array\n",
    "    # first (mfcc_features.shape[1]+filterbank_features.shape[1])) elements are for the first phoneme\n",
    "    feature_length_for_each_phoneme = (mfcc_features.shape[1]+filterbank_features.shape[1])\n",
    "    result = np.zeros((1, (max(phoneme_to_index.values())+1)*feature_length_for_each_phoneme), dtype=np.float64)\n",
    "\n",
    "    # check if a phoneme is inside a word\n",
    "    def inside(p, w):\n",
    "        p_start = p[1]\n",
    "        p_end = p [2]\n",
    "        w_start = w[2]\n",
    "        w_end = w[3]\n",
    "        if p_start >= w_start-2 and p_end <= w_end +2:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    # find corresponding phonemes in each word\n",
    "    m_features = {}\n",
    "    f_features = {}\n",
    "    phoneme_counts = {}\n",
    "    for w in word_segments[1:-1]:\n",
    "        phonemes = []\n",
    "        for p in phoneme_segments:\n",
    "            if inside(p, w):\n",
    "                phonemes.append(p)\n",
    "        # if phonemes are matched\n",
    "        if len(w[1].split(\" \")) == len(phonemes):\n",
    "            # add extracted features to feature dictionary\n",
    "            index = 0\n",
    "            for correct_phonemes in w[1].split(\" \"):\n",
    "                if correct_phonemes in phoneme_to_index and phoneme_to_index[correct_phonemes] != -1:\n",
    "                    if not correct_phonemes in phoneme_counts:\n",
    "                        phoneme_counts[correct_phonemes] = phonemes[index][2] - phonemes[index][1] + 1\n",
    "                        m_features[correct_phonemes] = np.sum(mfcc_features[phonemes[index][1]:phonemes[index][2]+1], axis=0)\n",
    "                        f_features[correct_phonemes] = np.sum(filterbank_features[phonemes[index][1]:phonemes[index][2]+1], axis=0)\n",
    "                    else:\n",
    "                        phoneme_counts[correct_phonemes] += phonemes[index][2] - phonemes[index][1] + 1\n",
    "                        m_features[correct_phonemes] += np.sum(mfcc_features[phonemes[index][1]:phonemes[index][2]+1], axis=0)\n",
    "                        f_features[correct_phonemes] += np.sum(filterbank_features[phonemes[index][1]:phonemes[index][2]+1], axis=0)\n",
    "                index += 1\n",
    "\n",
    "    # average all phoneme features for each phoneme and add it to feature array\n",
    "    for p in phoneme_counts.keys():\n",
    "        if p in phoneme_to_index and phoneme_to_index[p] != -1:\n",
    "            m_features[p] = m_features[p] / phoneme_counts[p]\n",
    "            f_features[p] = f_features[p] / phoneme_counts[p]\n",
    "            result[0,phoneme_to_index[p]*feature_length_for_each_phoneme:(phoneme_to_index[p]+1)*feature_length_for_each_phoneme] = np.concatenate((m_features[p], f_features[p]), axis=0).reshape(1,-1)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypothesis: my voice is my password\n",
      "Detailed segments:\n",
      "('<s>', 0, 0, 3)\n",
      "('my', -1527, 4, 16)\n",
      "('voice', -1, 17, 47)\n",
      "('is', 0, 48, 65)\n",
      "('my', -9505, 66, 79)\n",
      "('password', 0, 80, 134)\n",
      "('</s>', 0, 135, 152)\n",
      "Segments Phonemes: [('<s>', 'SIL', 0, 3), ('my', 'M AY', 4, 16), ('voice', 'V OY S', 17, 47), ('is', 'IH Z', 48, 65), ('my', 'M AY', 66, 79), ('password', 'P AE S W ER D', 80, 134), ('</s>', 'SIL', 135, 152)]\n",
      "Best phonetic segments: [('SIL', 0, 3), ('L', 4, 9), ('AY', 10, 16), ('V', 17, 25), ('OY', 26, 36), ('Z', 37, 47), ('IH', 48, 56), ('S', 57, 65), ('L', 66, 71), ('EH', 72, 78), ('L', 79, 85), ('AA', 86, 98), ('Z', 99, 107), ('OY', 108, 123), ('TH', 124, 134), ('V', 135, 152)]\n"
     ]
    }
   ],
   "source": [
    "# example: T_1000003.wav\n",
    "print(\"example file: T_1000003.wav\")\n",
    "word_segments = word_seg(os.path.join(training_data_path, fileName), verbose=True)\n",
    "phoneme_segments = phoneme_seg(os.path.join(training_data_path, fileName), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing sample 100\n",
      "processing sample 200\n",
      "processing sample 300\n",
      "processing sample 400\n",
      "processing sample 500\n",
      "processing sample 600\n",
      "processing sample 700\n",
      "processing sample 800\n",
      "processing sample 900\n",
      "processing sample 1000\n",
      "processing sample 1100\n",
      "processing sample 1200\n",
      "processing sample 1300\n",
      "processing sample 1400\n",
      "processing sample 1500\n",
      "processing sample 1600\n",
      "processing sample 1700\n",
      "processing sample 1800\n",
      "processing sample 1900\n",
      "processing sample 2000\n",
      "processing sample 2100\n",
      "processing sample 2200\n",
      "processing sample 2300\n",
      "processing sample 2400\n",
      "processing sample 2500\n",
      "processing sample 2600\n",
      "processing sample 2700\n",
      "processing sample 2800\n",
      "processing sample 2900\n",
      "processing sample 3000\n"
     ]
    }
   ],
   "source": [
    "features_for_all_samples = None\n",
    "labels = None\n",
    "sample_count = 0\n",
    "\n",
    "# generate Phoneme segmentation and features for each training file\n",
    "for record in training_set_description:\n",
    "    # if this line is not empty\n",
    "    if len(record)>10:\n",
    "        fileName = record.split(\" \")[0]\n",
    "        label = 1 if record.split(\" \")[1] == 'genuine' else 0  # label is 1 for genuine data\n",
    "        dictionary = \"ASVspoof2017_\"+ str(int(record.split(\" \")[3][1:])) + \".dict\"\n",
    "        \n",
    "       \n",
    "        # extract features of entire audio\n",
    "        mfcc_features, filterbank_features = extract_mfcc_filterbank_features(os.path.join(training_data_path, fileName), show=False)\n",
    "\n",
    "        # phoneme segmentation\n",
    "        # word segmentation is much more accurate, so we perform word segmentation first and use it to guide phoneme extraction\n",
    "        word_segments = word_seg(os.path.join(training_data_path, fileName), verbose=False)\n",
    "        phoneme_segments = phoneme_seg(os.path.join(training_data_path, fileName), verbose=False)\n",
    "\n",
    "        # extract features for each phoneme\n",
    "        result = extract_feature(mfcc_features, filterbank_features,  word_segments, phoneme_segments)\n",
    "        \n",
    "        # add feature to features_for_all_samples\n",
    "        if sample_count == 0:\n",
    "            feature_length_for_each_phoneme = (mfcc_features.shape[1]+filterbank_features.shape[1])\n",
    "            features_for_all_samples = np.zeros((len(training_set_description), (max(phoneme_to_index.values())+1)*feature_length_for_each_phoneme), dtype=np.float64)\n",
    "            labels = np.zeros((len(training_set_description), 1), dtype=np.int32)\n",
    "            \n",
    "        features_for_all_samples[sample_count,:] = result\n",
    "        labels[sample_count] = label\n",
    "        sample_count += 1\n",
    "        \n",
    "        if sample_count%50 == 0:\n",
    "            print(\"processing sample \" + str(sample_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change 0 (missing value) into mean values of non-zero elements for each column\n",
    "column_mean = np.true_divide(features_for_all_samples.sum(0),(features_for_all_samples!=0).sum(0))\n",
    "inds = np.where(features_for_all_samples == 0)\n",
    "# replace the index\n",
    "features_for_all_samples[inds] = np.take(column_mean, inds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "with open(os.path.join(data_path,'training_features_for_all_samples.npy'), 'wb') as f:\n",
    "    np.save(f, features_for_all_samples)\n",
    "# 1 for genuine data, 0 for recorded data\n",
    "with open(os.path.join(data_path,'training_labels.npy'), 'wb') as f:\n",
    "    np.save(f, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.57245515  0.64325575 -0.5824464  ...  0.95182087  0.70603924\n",
      "   0.32129658]\n",
      " [ 0.45140943  0.70227568 -0.44508289 ...  0.95182087  0.70603924\n",
      "   0.32129658]\n",
      " [ 0.67336976  0.8854558  -1.69192739 ...  0.95182087  0.70603924\n",
      "   0.32129658]\n",
      " ...\n",
      " [ 0.385312    0.67256589 -0.68538314 ...  0.95182087  0.70603924\n",
      "   0.32129658]\n",
      " [ 0.45140943  0.70227568 -0.44508289 ...  0.95182087  0.70603924\n",
      "   0.32129658]\n",
      " [ 0.45140943  0.70227568 -0.44508289 ...  0.95182087  0.70603924\n",
      "   0.32129658]]\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "with open(os.path.join(data_path,'training_features_for_all_samples.npy'), 'rb') as f:\n",
    "    temp = np.load(f)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_for_all_samples_dev = None\n",
    "# labels_dev = None\n",
    "# sample_count = 0\n",
    "# model_path = get_model_path()\n",
    "\n",
    "# # generate Phoneme segmentation and features for each dev file\n",
    "# for record in dev_set_description:\n",
    "#     # if this line is not empty\n",
    "#     if len(record)>10:\n",
    "#         fileName = record.split(\" \")[0]\n",
    "#         label = 1 if record.split(\" \")[1] == 'genuine' else 0  # label is 1 for genuine data\n",
    "#         dictionary = \"ASVspoof2017_\"+ str(int(record.split(\" \")[3][1:])) + \".dict\"\n",
    "        \n",
    "       \n",
    "#         # extract features of entire audio\n",
    "#         mfcc_features, filterbank_features = extract_mfcc_filterbank_features(os.path.join(dev_data_path, fileName), show=False)\n",
    "\n",
    "#         # phoneme segmentation\n",
    "#         # word segmentation is much more accurate, so we perform word segmentation first and use it to guide phoneme extraction\n",
    "#         word_segments = word_seg(os.path.join(dev_data_path, fileName), verbose=False)\n",
    "#         phoneme_segments = phoneme_seg(os.path.join(dev_data_path, fileName), verbose=False)\n",
    "\n",
    "#         # extract features for each phoneme\n",
    "#         result = extract_feature(mfcc_features, filterbank_features,  word_segments, phoneme_segments)\n",
    "        \n",
    "#         # add feature to features_for_all_samples_dev\n",
    "#         if sample_count == 0:\n",
    "#             feature_length_for_each_phoneme = (mfcc_features.shape[1]+filterbank_features.shape[1])\n",
    "#             features_for_all_samples_dev = np.zeros((len(dev_set_description), (max(phoneme_to_index.values())+1)*feature_length_for_each_phoneme), dtype=np.float64)\n",
    "#             labels_dev = np.zeros((len(dev_set_description), 1), dtype=np.int32)\n",
    "            \n",
    "#         features_for_all_samples_dev[sample_count,:] = result\n",
    "#         labels_dev[sample_count] = label\n",
    "#         sample_count += 1\n",
    "        \n",
    "#         if sample_count%100 == 0:\n",
    "#             print(\"processing sample \" + str(sample_count))\n",
    "\n",
    "\n",
    "# # change 0 into mean values of non-zero elements for each column\n",
    "# column_mean = np.true_divide(features_for_all_samples_dev.sum(0),(features_for_all_samples_dev!=0).sum(0))\n",
    "# inds = np.where(features_for_all_samples_dev == 0)\n",
    "# # replace the index\n",
    "# features_for_all_samples_dev[inds] = np.take(column_mean, inds[1])\n",
    "\n",
    "\n",
    "# # save data\n",
    "# with open(os.path.join(data_path,'dev_features_for_all_samples.npy'), 'wb') as f:\n",
    "#     np.save(f, features_for_all_samples_dev)\n",
    "# # 1 for genuine data, 0 for recorded data\n",
    "# with open(os.path.join(data_path,'dev_labels.npy'), 'wb') as f:\n",
    "#     np.save(f, labels_dev)\n",
    "\n",
    "\n",
    "# # load data\n",
    "# with open(os.path.join(data_path,'dev_features_for_all_samples.npy'), 'rb') as f:\n",
    "#     temp2 = np.load(f)\n",
    "# print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04143687 0.082547   0.11454896 0.14260813 0.16936953 0.19265732\n",
      " 0.2151152  0.23643237 0.25719586 0.27602773 0.2935838  0.31045678\n",
      " 0.32616446 0.34122565 0.35626538 0.3706954  0.38444929 0.39760613\n",
      " 0.40951139 0.42119984 0.43193385 0.44261332 0.45294229 0.46313739\n",
      " 0.47328631 0.48329335 0.49287111 0.50215313 0.51108246 0.51993125\n",
      " 0.52865001 0.53713643 0.54538499 0.55353598 0.56155977 0.56934365\n",
      " 0.57708437 0.58452093 0.59185069 0.59899264 0.60609598 0.61310737\n",
      " 0.62004005 0.6267286  0.63333646 0.63984732 0.64619818 0.65246628\n",
      " 0.65867138 0.66478739 0.67068895 0.67643495 0.68207445 0.68759874\n",
      " 0.69302495 0.69832692 0.70351239 0.70864886 0.71362957 0.71854857\n",
      " 0.72338119 0.72807644 0.73272605 0.73729598 0.74176775 0.7462275\n",
      " 0.75059491 0.75499471 0.75923416 0.76341361 0.76744389 0.77146034\n",
      " 0.77535835 0.77918068 0.782965   0.78665471 0.7902891  0.79384443\n",
      " 0.79738046 0.8008519  0.80424131 0.80756475 0.8108374  0.81407819\n",
      " 0.8172001  0.82025303 0.82324738 0.82622253 0.82911986 0.83202226\n",
      " 0.83484203 0.83764145 0.84042153 0.84315076 0.84581187 0.84829864\n",
      " 0.8508946  0.85347115 0.85600691 0.85845257 0.86085635 0.86323997\n",
      " 0.86556475 0.86786508 0.87017344 0.87242926 0.87462732 0.87683565\n",
      " 0.87898568 0.88109382 0.88317594 0.88522892 0.8872349  0.88921533\n",
      " 0.89116449 0.89309498 0.89493154 0.8968263  0.89870751 0.90057131\n",
      " 0.90237355 0.90410881 0.90583506 0.90751704 0.90917952 0.91086838\n",
      " 0.91249787 0.91409875 0.9156818  0.91725685 0.91879837 0.92031705\n",
      " 0.9218158  0.92328245 0.92472668 0.92606778 0.92749356 0.92890174\n",
      " 0.93028047 0.93166524 0.93298356 0.93429184 0.93556911 0.93683717\n",
      " 0.93808814 0.93931587 0.94052828 0.94172883 0.9429147  0.94409507\n",
      " 0.94503204 0.94598522 0.94694895 0.94792183 0.94905599 0.95017858\n",
      " 0.95129072 0.9523935  0.95347598 0.95448414 0.95549756 0.95655653\n",
      " 0.9575914  0.95863123 0.95967676 0.96053575 0.96141568 0.96232763\n",
      " 0.96325595 0.96402491 0.96480741 0.96560632 0.96642572 0.96723638\n",
      " 0.96808404 0.96892752 0.9697158  0.97045928 0.97119579 0.97192369\n",
      " 0.97263577 0.97326224 0.97391418 0.97460174 0.97528483 0.9759563\n",
      " 0.97659563 0.97721747 0.97782582 0.97841503 0.9789948  0.97956709\n",
      " 0.98012048 0.9806754  0.98120319 0.98172437 0.98217432 0.9826457\n",
      " 0.98311065 0.9836125  0.98410659 0.98459494 0.98502122 0.98544158\n",
      " 0.98585213 0.98624953 0.9866419  0.98702885 0.98740563 0.98777471\n",
      " 0.98813779 0.98841629 0.98869971 0.9890476  0.98933812 0.98967599\n",
      " 0.989978   0.99027683 0.99060575 0.99092959 0.9912492  0.991568\n",
      " 0.99181576 0.99207391 0.99233466 0.99260537 0.99284037 0.99305969\n",
      " 0.99328545 0.99350922 0.99371018 0.99391812 0.99412355 0.99431565\n",
      " 0.99450361 0.99468497 0.99485936 0.99502843 0.99518822 0.99534131\n",
      " 0.9954924  0.99563734 0.99577928 0.99591826 0.99603972 0.99616988\n",
      " 0.99630044 0.9964266  0.99655402 0.99667268 0.99678707 0.99689827\n",
      " 0.99700708 0.99711486 0.9972198  0.99732312 0.99742335 0.99751807\n",
      " 0.99761044 0.99770101 0.99778869 0.99787486 0.99795802 0.99803784\n",
      " 0.99811331 0.99818628 0.99818879 0.99819157 0.99819452 0.99819874\n",
      " 0.99820317 0.99820869 0.9982148  0.99822198 0.99823018 0.99823935\n",
      " 0.99831988 0.99839405 0.99846317 0.99847316 0.99848437 0.99849728\n",
      " 0.99851136 0.99852313 0.99853354 0.99854876 0.99861251 0.99862844\n",
      " 0.9986903  0.99875704 0.99881616 0.99886993 0.99892692 0.9989828\n",
      " 0.99902579 0.99907387 0.99912097 0.99916002 0.99919821 0.99925938\n",
      " 0.99930963 0.99935463 0.99942202 0.99947214 0.999508   0.99952647\n",
      " 0.99954375 0.99956069 0.99958034 0.99960044 0.99962232 0.99964489\n",
      " 0.9996681  0.9996921  0.99971984 0.99974646 0.99978049 0.99981035\n",
      " 0.9998434  0.99987404 0.99990521 0.99993752 0.99997115 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# dimensional reduction to reduce size and speed up training/testing\n",
    "# This aligns with the goal of void\n",
    "\n",
    "# using vanilla PCA\n",
    "all_data = temp\n",
    "# all_data = np.concatenate((temp, temp2), axis=0)\n",
    "\n",
    "covariance = np.cov(all_data.T)\n",
    "eigen_values, eigen_vectors = np.linalg.eig(covariance)\n",
    "eigen_values = eigen_values.real\n",
    "# find out how many components are redundent\n",
    "cumulative_variance = []\n",
    "sum_eigen_values = sum(eigen_values)\n",
    "for i in eigen_values:\n",
    "     cumulative_variance.append((i/sum_eigen_values))\n",
    "cumulative_variance = np.cumsum(cumulative_variance)\n",
    "print(cumulative_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.759921    2.39484344  0.77091857 ... -0.52354568 -0.18408894\n",
      "   0.70522357]\n",
      " [ 4.22751347  1.92340483 -0.09654887 ... -0.05079488  0.13875081\n",
      "   0.36010536]\n",
      " [ 5.14014553  1.84676281  0.8697217  ... -0.26075501  0.12936591\n",
      "   0.39289889]\n",
      " ...\n",
      " [ 4.42613824  2.8044536   0.03624756 ... -0.03244927  0.13101899\n",
      "   0.7934797 ]\n",
      " [ 4.22751347  1.92340483 -0.09654887 ... -0.05079488  0.13875081\n",
      "   0.36010536]\n",
      " [ 3.15618277  3.15087082  1.76838553 ... -0.22677067  0.25125359\n",
      "   0.24818135]]\n"
     ]
    }
   ],
   "source": [
    "# use 165 components for 95% variance\n",
    "projection = (eigen_vectors.T[:][:165]).T\n",
    "projected_features_training = temp.dot(projection)\n",
    "print(projected_features_training)\n",
    "# projected_features_dev = temp2.dot(projection)\n",
    "# print(projected_features_dev)\n",
    "\n",
    "# save data\n",
    "with open(os.path.join(data_path,'training_features_for_all_samples_PCA.npy'), 'wb') as f:\n",
    "    np.save(f, projected_features_training)\n",
    "# with open(os.path.join(data_path,'dev_features_for_all_samples_PCA.npy'), 'wb') as f:\n",
    "#     np.save(f, projected_features_dev)\n",
    "with open(os.path.join(data_path,'projection_PCA.npy'), 'wb') as f:\n",
    "    np.save(f, projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
